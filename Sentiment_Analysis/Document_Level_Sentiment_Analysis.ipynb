{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MTWtWohZDkD"
   },
   "source": [
    "## Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tdQQfdrQZDkE"
   },
   "source": [
    "## Task 1.1: Document-level Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H_lhmp5IZDkE"
   },
   "source": [
    "Build a Bidirectional Recurrent Neural Network (RNN) model for multi-class sentiment classification. Compare the performance with a Unidirectional RNN model. Your model (each) shall\n",
    "include:\n",
    "\n",
    "- RNN network that learns sentence representation from input sequences.\n",
    "- Fully connected network that predicts sentiment label, given the learnt state representation.\n",
    "\n",
    "\n",
    "Train the model by using data iterator and batch generator. Evaluate the trained model on\n",
    "the provided test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13GNLSaWu7np"
   },
   "source": [
    "## Unidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FlYnGJLTZDkF",
    "outputId": "4c5c39fe-a860-439b-bb19-a9dce8557773"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20181592\\AppData\\Local\\Continuum\\anaconda3\\envs\\py3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "import _pickle as cPickle\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import operator\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM, Input, Bidirectional\n",
    "from keras.models import Model\n",
    "import keras.optimizers as opt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "kvvt_fUlb861",
    "outputId": "326dd0f1-5c0f-4da8-abf2-854f2302d30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8hcGkWajb_aO",
    "outputId": "c1994786-2e89-4a93-98b6-6078a181d5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks\n"
     ]
    }
   ],
   "source": [
    "cd drive/My Drive/Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_vwhzseZDkO"
   },
   "outputs": [],
   "source": [
    "data_path = 'data/doc_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AamP9B4dZDkQ"
   },
   "outputs": [],
   "source": [
    "num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
    "\n",
    "def create_vocab(domain, data_path, maxlen=0, vocab_size=0):\n",
    "    \n",
    "    print('Creating vocab ...')\n",
    "\n",
    "    f = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "\n",
    "    total_words, unique_words = 0, 0\n",
    "    word_freqs = {}\n",
    "\n",
    "    fin = codecs.open(f, 'r', 'utf-8')\n",
    "    for line in fin:\n",
    "        words = line.split()\n",
    "        if maxlen > 0 and len(words) > maxlen:\n",
    "            continue\n",
    "\n",
    "        for w in words:\n",
    "            if not bool(num_regex.match(w)):\n",
    "                try:\n",
    "                    word_freqs[w] += 1\n",
    "                except KeyError:\n",
    "                    unique_words += 1\n",
    "                    word_freqs[w] = 1\n",
    "                total_words += 1\n",
    "\n",
    "    print ('  %i total words, %i unique words' % (total_words, unique_words))\n",
    "    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n",
    "    index = len(vocab)\n",
    "    for word, _ in sorted_word_freqs:\n",
    "        vocab[word] = index\n",
    "        index += 1\n",
    "        if vocab_size > 0 and index > vocab_size + 2:\n",
    "            break\n",
    "    if vocab_size > 0:\n",
    "        print (' keep the top %i words' % vocab_size)\n",
    "\n",
    "  \n",
    "    return vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0KWSIFwZDkS"
   },
   "outputs": [],
   "source": [
    "def create_data(vocab, text_path, label_path, domain, skip_top, skip_len, replace_non_vocab):\n",
    "    \n",
    "    data = []\n",
    "    label = [] # {pos: 0, neg: 1, neu: 2}\n",
    "    \n",
    "    f = codecs.open(text_path, 'r', 'utf-8')\n",
    "    f_l = codecs.open(label_path, 'r', 'utf-8')\n",
    "    \n",
    "    num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n",
    "    pos_count, neg_count, neu_count = 0, 0, 0\n",
    "    max_len = 0\n",
    "\n",
    "    for line, score in zip(f, f_l):\n",
    "        word_indices = []\n",
    "        words = line.split()\n",
    "        if skip_len > 0 and len(words) > skip_len:\n",
    "            continue\n",
    "\n",
    "        score = float(score.strip())\n",
    "        if score < 3:\n",
    "            neg_count += 1\n",
    "            label.append(1)\n",
    "        elif score > 3:\n",
    "            pos_count += 1\n",
    "            label.append(0)\n",
    "        else:\n",
    "            neu_count += 1\n",
    "            label.append(2)\n",
    "          \n",
    "        for word in words:\n",
    "            if bool(num_regex.match(word)):\n",
    "                word_indices.append(vocab['<num>'])\n",
    "                num_hit += 1\n",
    "            elif word in vocab:\n",
    "                word_ind = vocab[word]\n",
    "                if skip_top > 0 and word_ind < skip_top + 3:\n",
    "                    skip_top_hit += 1\n",
    "                else:\n",
    "                    word_indices.append(word_ind)\n",
    "            else:\n",
    "                if replace_non_vocab:\n",
    "                    word_indices.append(vocab['<unk>'])\n",
    "                unk_hit += 1\n",
    "            total += 1\n",
    "\n",
    "        if len(word_indices) > max_len:\n",
    "            max_len = len(word_indices)\n",
    "\n",
    "        data.append(word_indices)\n",
    "\n",
    "    f.close()\n",
    "    f_l.close()\n",
    "\n",
    "    print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n",
    "\n",
    "    print (domain)\n",
    "    print( 'pos count: ', pos_count )\n",
    "    print( 'neg count: ', neg_count )\n",
    "    print( 'neu count: ', neu_count )\n",
    "\n",
    "    return np.array(data), np.array(label), max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zAIC_dGJZDkU"
   },
   "outputs": [],
   "source": [
    "def prepare_data(domain, data_path, vocab_size, skip_top=0, skip_len=0, replace_non_vocab=1):\n",
    "    \n",
    "    print(domain)\n",
    "\n",
    "    assert domain in ['amazon_electronics', 'yelp14']\n",
    "\n",
    "    vocab = create_vocab(domain, data_path, skip_len, vocab_size)\n",
    "    #print(vocab)\n",
    "\n",
    "    text_path = os.path.join(data_path,'%s_text.txt'%(domain))\n",
    "    score_path = os.path.join(data_path,'%s_label.txt'%(domain))\n",
    "\n",
    "    data, label, max_len = create_data(vocab, text_path, score_path, domain, skip_top, \\\n",
    "                                       skip_len, replace_non_vocab)\n",
    "\n",
    "    return vocab, data, label, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbsM4S_hZDkW"
   },
   "outputs": [],
   "source": [
    "# choose domain data to train\n",
    "domain_name = 'amazon_electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "4D0wK6OSZDkZ",
    "outputId": "1453844b-262e-434a-9c29-dfd21386be0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_electronics\n",
      "Creating vocab ...\n",
      "  3440972 total words, 39122 unique words\n",
      " keep the top 10000 words\n",
      "  <num> hit rate: 1.04%, <unk> hit rate: 1.56%\n",
      "amazon_electronics\n",
      "pos count:  10000\n",
      "neg count:  10000\n",
      "neu count:  10000\n"
     ]
    }
   ],
   "source": [
    "vocab, data_list, label_list, overall_maxlen = prepare_data(domain_name, data_path, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFto63C6ZDkb"
   },
   "outputs": [],
   "source": [
    "idx_words = dict((v,k) for (k,v) in vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-ah9J-JZDkf"
   },
   "outputs": [],
   "source": [
    "data_path_save = 'Assign3DataStorage/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1sSWysVPZDkh"
   },
   "outputs": [],
   "source": [
    "def read_pickle(path_data, file_name):\n",
    "\n",
    "    f = open(os.path.join(path_data, file_name), 'rb')\n",
    "    read_file = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return read_file\n",
    "\n",
    "def save_pickle(path_data, file_name, data):\n",
    "\n",
    "    f = open(os.path.join(path_data, file_name), 'wb')\n",
    "    cPickle.dump(data, f)\n",
    "    print(\" file saved to: %s\"%(os.path.join(path_data, file_name)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eYzedUW0ZDkk",
    "outputId": "602e1194-f32d-42de-81fd-4c9260ae98ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/words_idx.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'words_idx.pkl', vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yc69Zb44ZDkm",
    "outputId": "d196f53d-ffa3-4eee-c852-855456130de9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/idx_words.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'idx_words.pkl', idx_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KRmIZeleZDko",
    "outputId": "c6f9647b-3365-4ef9-d286-dcaea06e8567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/data.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'data.pkl', data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eDkScGLEZDkq",
    "outputId": "0c861365-7b7f-4a8f-98b6-59e35135e9fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: Assign3DataStorage/label.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(data_path_save, 'label.pkl', label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "322613UpZDks"
   },
   "source": [
    "### End of Preprocessing\n",
    "\n",
    "### Model training, testing and conclusion summary of these are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTi7HvMaZDkv"
   },
   "outputs": [],
   "source": [
    "words_idx = read_pickle(data_path, 'words_idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7o1JLnPZDky"
   },
   "outputs": [],
   "source": [
    "idx_words = read_pickle(data_path, 'idx_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8G5-kFUxZDk2"
   },
   "outputs": [],
   "source": [
    "data = read_pickle(data_path, 'data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9B9BHH2ZDk5"
   },
   "outputs": [],
   "source": [
    "label = read_pickle(data_path, 'label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WrFfdvYZDk7"
   },
   "outputs": [],
   "source": [
    "rand_idx = np.arange(len(data))\n",
    "np.random.shuffle(rand_idx)\n",
    "\n",
    "data = data[rand_idx]\n",
    "label = to_categorical(label)[rand_idx]\n",
    "\n",
    "data_size = len(data)\n",
    "\n",
    "test_x = data[0:6000]\n",
    "test_y = label[0:6000]\n",
    "\n",
    "dev_x = data[6000:10800]\n",
    "dev_y = label[6000:10800]\n",
    "\n",
    "train_x = data[10800:int(data_size)]\n",
    "train_y = label[10800:int(data_size)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-pnMCOOPZDk9"
   },
   "outputs": [],
   "source": [
    "maxlen = 300\n",
    "words_idx = [x for (x, _) in sorted(words_idx.items(), key=operator.itemgetter(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cOa6UpLnZDlA"
   },
   "outputs": [],
   "source": [
    "train_x_ = sequence.pad_sequences(train_x, maxlen)\n",
    "dev_x_ = sequence.pad_sequences(dev_x, maxlen)\n",
    "test_x_ = sequence.pad_sequences(test_x, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZfs4bfKZDlC"
   },
   "outputs": [],
   "source": [
    "train_x_ = np.array(train_x_)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "dev_x_ = np.array(dev_x_)\n",
    "dev_y = np.array(dev_y)\n",
    "\n",
    "test_x_ = np.array(test_x_)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsMZENHJZDlE"
   },
   "outputs": [],
   "source": [
    "class Dataiterator():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, X, y, seq_length=32, decoder_dim=300, batch_size=32):      \n",
    "        self.X = X \n",
    "        self.y = y \n",
    "        self.num_data = len(X) # total number of examples\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "        batch_X = self.X[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y = self.y[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        return batch_X, batch_y\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X, self.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGNvIJq27wu2"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZE6J0oSXZDlH"
   },
   "outputs": [],
   "source": [
    "sentence_input = Input(shape=(300,), dtype='int32', name='sentence_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "5pO9OyJEZDlJ",
    "outputId": "a0ddc9cf-1763-4370-e743-040459add59e"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)\n",
    "drop = Dropout(0.25)(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci_lCnzGZDlL"
   },
   "outputs": [],
   "source": [
    "# 1 no embd drop, lstm dropout = 0.5, reccr drop = 0.1\n",
    "dropout6 = 0.5\n",
    "recurrent_dropout6 = 0.1\n",
    "lstm_layer6 = LSTM(300, return_sequences=False, dropout=dropout6, \\\n",
    "              recurrent_dropout=recurrent_dropout6, name='lstm6')(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tv4noVsU1Vsh"
   },
   "outputs": [],
   "source": [
    "# 2 embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.1\n",
    "dropout4 = 0.5\n",
    "recurrent_dropout4 = 0.1\n",
    "lstm_layer4 = LSTM(300, return_sequences=False, dropout=dropout4, \\\n",
    "              recurrent_dropout=recurrent_dropout4, name='lstm4')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anCOg4An1Vx4"
   },
   "outputs": [],
   "source": [
    "# 3 embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.2\n",
    "dropout5 = 0.5\n",
    "recurrent_dropout5 = 0.2\n",
    "lstm_layer5 = LSTM(300, return_sequences=False, dropout=dropout5, \\\n",
    "              recurrent_dropout=recurrent_dropout5, name='lstm5')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MZVztISZDlO"
   },
   "outputs": [],
   "source": [
    "densed6 = Dense(3, name='dense')(lstm_layer6)\n",
    "probs6 = Activation('softmax')(densed6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ULRa_eRk4lzO"
   },
   "outputs": [],
   "source": [
    "densed4 = Dense(3, name='dense')(lstm_layer4)\n",
    "probs4 = Activation('softmax')(densed4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRp3c0uI4l31"
   },
   "outputs": [],
   "source": [
    "densed5 = Dense(3, name='dense')(lstm_layer5)\n",
    "probs5 = Activation('softmax')(densed5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NfJt5RDkZDlS"
   },
   "outputs": [],
   "source": [
    "model6 = Model(inputs=[sentence_input], outputs=probs6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsfseUbi4x1Y"
   },
   "outputs": [],
   "source": [
    "model4 = Model(inputs=[sentence_input], outputs=probs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TsHrtvKo4x5u"
   },
   "outputs": [],
   "source": [
    "model5 = Model(inputs=[sentence_input], outputs=probs5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KPUJfQB945ma"
   },
   "outputs": [],
   "source": [
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "cIz2Yr5iZDlT",
    "outputId": "f99146a6-0b2f-4663-dd21-c345fa48742e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               721200    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 3,723,003\n",
      "Trainable params: 3,723,003\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model6.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model6\")\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_eVQlsEX49EI"
   },
   "outputs": [],
   "source": [
    "model4.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model4\")\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XHjkY3pP49A-"
   },
   "outputs": [],
   "source": [
    "model5.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"summary of Model5\")\n",
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyjqhu5WZDlW"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ytCdoIMZLMdF",
    "outputId": "cb153ce3-b573-4cb2-f6e0-a9e3bdaee478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLJce3JMZDlX"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x_)/batch_size\n",
    "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fzEpDbA0ZDlZ"
   },
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x_)/batch_size\n",
    "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1LOk0TZZDla"
   },
   "outputs": [],
   "source": [
    "test_steps_epoch = len(test_x_)/batch_size\n",
    "batch_test_iter = Dataiterator(test_x_, test_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hr7hwNZZDlc"
   },
   "outputs": [],
   "source": [
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=12),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "\n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "\n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "\n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rCsq1fyt9RFC"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 655
    },
    "colab_type": "code",
    "id": "NVYpk1MyZDle",
    "outputId": "9598bd59-9858-4883-fc4a-0472e876e0d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 440s 733ms/step - loss: 0.9275 - categorical_accuracy: 0.5528 - val_loss: 0.8156 - val_categorical_accuracy: 0.6204\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.7730 - categorical_accuracy: 0.6562 - val_loss: 0.7854 - val_categorical_accuracy: 0.6360\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.7033 - categorical_accuracy: 0.6928 - val_loss: 0.8685 - val_categorical_accuracy: 0.5979\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 436s 727ms/step - loss: 0.6401 - categorical_accuracy: 0.7302 - val_loss: 0.7833 - val_categorical_accuracy: 0.6458\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.5846 - categorical_accuracy: 0.7596 - val_loss: 0.8080 - val_categorical_accuracy: 0.6475\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.5304 - categorical_accuracy: 0.7837 - val_loss: 0.9257 - val_categorical_accuracy: 0.6448\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 433s 721ms/step - loss: 0.4852 - categorical_accuracy: 0.8096 - val_loss: 0.8485 - val_categorical_accuracy: 0.6596\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.4355 - categorical_accuracy: 0.8301 - val_loss: 0.8774 - val_categorical_accuracy: 0.6519\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.3870 - categorical_accuracy: 0.8530 - val_loss: 0.9241 - val_categorical_accuracy: 0.6356\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 431s 719ms/step - loss: 0.3436 - categorical_accuracy: 0.8698 - val_loss: 0.9710 - val_categorical_accuracy: 0.6375\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 433s 721ms/step - loss: 0.2976 - categorical_accuracy: 0.8878 - val_loss: 1.0683 - val_categorical_accuracy: 0.6365\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 434s 723ms/step - loss: 0.2505 - categorical_accuracy: 0.9097 - val_loss: 1.2275 - val_categorical_accuracy: 0.6315\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 437s 728ms/step - loss: 0.2252 - categorical_accuracy: 0.9178 - val_loss: 1.2992 - val_categorical_accuracy: 0.6202\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 435s 725ms/step - loss: 0.1856 - categorical_accuracy: 0.9335 - val_loss: 1.3622 - val_categorical_accuracy: 0.6265\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 433s 722ms/step - loss: 0.1616 - categorical_accuracy: 0.9439 - val_loss: 1.4154 - val_categorical_accuracy: 0.6231\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 432s 720ms/step - loss: 0.1314 - categorical_accuracy: 0.9532 - val_loss: 1.5199 - val_categorical_accuracy: 0.6281\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 432s 721ms/step - loss: 0.1070 - categorical_accuracy: 0.9630 - val_loss: 1.7851 - val_categorical_accuracy: 0.6302\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 430s 716ms/step - loss: 0.0938 - categorical_accuracy: 0.9674 - val_loss: 1.8741 - val_categorical_accuracy: 0.6235\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 431s 719ms/step - loss: 0.0756 - categorical_accuracy: 0.9746 - val_loss: 2.0088 - val_categorical_accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "#Input shape as (300, )\n",
    "print(\"Training for model6\")\n",
    "train_generator(model3, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoL4wDwO5NOq"
   },
   "outputs": [],
   "source": [
    "print(\"Training for model4\")\n",
    "train_generator(model4, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mK2WBcnL5NSP"
   },
   "outputs": [],
   "source": [
    "print(\"Training for model5\")\n",
    "train_generator(model5, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0nLb2Ki9wzR"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "wi8iSvAVZDlh",
    "outputId": "821e197c-e288-480c-cb13-9c5b9a9e4020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 42s 7ms/step\n",
      "1.0987549308141074\n",
      "0.33866666666666667\n"
     ]
    }
   ],
   "source": [
    "#Input shape as (300, )\n",
    "print(\"Testing for model6\")\n",
    "loss, accuracy = model3.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) #was 63.33, re-execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrxcxzNR5TZ1"
   },
   "outputs": [],
   "source": [
    "print(\"Testing for model4\")\n",
    "loss, accuracy = model4.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5C_IiXb5Te4"
   },
   "outputs": [],
   "source": [
    "print(\"Testing for model5\")\n",
    "loss, accuracy = model5.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p__h3JT8ZDlt"
   },
   "source": [
    "## Bidirectional RNN Model for document level sentiment classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bw1HNQnXZDlu"
   },
   "outputs": [],
   "source": [
    "sentence_input = Input(shape = (maxlen, ), dtype = 'int32', name = 'sentence_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lCqblVR6_Jrx"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(words_idx)\n",
    "word_emb = Embedding(vocab_size, maxlen, mask_zero=True, name='word_emb')\n",
    "emb_output = word_emb(sentence_input)\n",
    "drop = Dropout(0.25)(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fcTTmZRf_Jvg"
   },
   "outputs": [],
   "source": [
    "# 1 no embd drop, lstmdrop = 0.5, recdrop = 0.1\n",
    "dropout1 = 0.5\n",
    "recurrent_dropout1 = 0.1\n",
    "lstm_layer1 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout1, \\\n",
    "              recurrent_dropout=recurrent_dropout1, name='lstm1'))(emb_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZStz9Vrh_JpT"
   },
   "outputs": [],
   "source": [
    "# 2 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.1\n",
    "dropout2 = 0.5\n",
    "recurrent_dropout2 = 0.1\n",
    "lstm_layer2 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout2, \\\n",
    "              recurrent_dropout=recurrent_dropout2, name='lstm2'))(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8nuZCbG_TMn"
   },
   "outputs": [],
   "source": [
    "# 3 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2\n",
    "dropout3 = 0.5\n",
    "recurrent_dropout3 = 0.2\n",
    "lstm_layer3 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout3, \\\n",
    "              recurrent_dropout=recurrent_dropout3, name='lstm3'))(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2, merge_mode = 'ave'\n",
    "dropout7 = 0.5\n",
    "recurrent_dropout7 = 0.2\n",
    "lstm_layer7 = Bidirectional(LSTM(maxlen, return_sequences=False, dropout=dropout7, \\\n",
    "              recurrent_dropout=recurrent_dropout7, name='lstm3'), merge_mode = 'ave')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtB15cMcaPWb"
   },
   "outputs": [],
   "source": [
    "densed1 = Dense(3, name='dense1')(lstm_layer1)\n",
    "probs1 = Activation('softmax')(densed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4SFGQbQhtP8"
   },
   "outputs": [],
   "source": [
    "densed2 = Dense(3, name='dense2')(lstm_layer2)\n",
    "probs2 = Activation('softmax')(densed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zDzCqccGhtTk"
   },
   "outputs": [],
   "source": [
    "densed3 = Dense(3, name='dense3')(lstm_layer3)\n",
    "probs3 = Activation('softmax')(densed3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "densed7 = Dense(3, name='dense3')(lstm_layer7)\n",
    "probs7 = Activation('softmax')(densed7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rSH0BdPAaPWd"
   },
   "outputs": [],
   "source": [
    "model1 = Model(inputs=[sentence_input], outputs=probs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OL_QxtmGh4rG"
   },
   "outputs": [],
   "source": [
    "model2 = Model(inputs=[sentence_input], outputs=probs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdyPd268h4v5"
   },
   "outputs": [],
   "source": [
    "model3 = Model(inputs=[sentence_input], outputs=probs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Model(inputs=[sentence_input], outputs=probs7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OOGbJE4sfbw"
   },
   "outputs": [],
   "source": [
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "_zb_sFGZaPWf",
    "outputId": "cec0c90b-9f0c-4f16-c8ca-a1b58eff6edd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 600)               1442400   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 1803      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,445,103\n",
      "Trainable params: 4,445,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model1\")\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8n1XXXWfiC1n"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model2\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyiqh4JwiC7N"
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model3\")\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary for Model7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_input (InputLayer)  (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "word_emb (Embedding)         (None, 300, 300)          3000900   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 300)               1442400   \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 3)                 903       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 4,444,203\n",
      "Trainable params: 4,444,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model7.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print(\"The summary for Model7\")\n",
    "model7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "peyjAqdkaPWi"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djtKTVp0aPWl"
   },
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x_)/batch_size\n",
    "batch_train_iter = Dataiterator(train_x_, train_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3gPBVT0yaPWn"
   },
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x_)/batch_size\n",
    "batch_val_iter = Dataiterator(dev_x_, dev_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iuluXwQyaPWp"
   },
   "outputs": [],
   "source": [
    "test_steps_epoch = len(test_x_)/batch_size\n",
    "batch_test_iter = Dataiterator(test_x_, test_y, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ov35iCM7aPWs"
   },
   "outputs": [],
   "source": [
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "\n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[X, y] for X, y in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "\n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[X, y] for X, y in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "\n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "colab_type": "code",
    "id": "_Q6VsVofaPWu",
    "outputId": "a527abbb-b87d-4b3f-a46d-18f05ffbd924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 1331s 2s/step - loss: 0.8923 - categorical_accuracy: 0.5780 - val_loss: 0.7570 - val_categorical_accuracy: 0.6621\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 1320s 2s/step - loss: 0.7168 - categorical_accuracy: 0.6852 - val_loss: 0.7202 - val_categorical_accuracy: 0.6737\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 1320s 2s/step - loss: 0.6425 - categorical_accuracy: 0.7255 - val_loss: 0.7411 - val_categorical_accuracy: 0.6615\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 1322s 2s/step - loss: 0.5686 - categorical_accuracy: 0.7628 - val_loss: 0.7206 - val_categorical_accuracy: 0.6817\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 1352s 2s/step - loss: 0.5077 - categorical_accuracy: 0.7946 - val_loss: 0.8369 - val_categorical_accuracy: 0.6725\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 1356s 2s/step - loss: 0.4487 - categorical_accuracy: 0.8234 - val_loss: 0.8080 - val_categorical_accuracy: 0.6706\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 1365s 2s/step - loss: 0.3935 - categorical_accuracy: 0.8460 - val_loss: 0.8641 - val_categorical_accuracy: 0.6677\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 1356s 2s/step - loss: 0.3378 - categorical_accuracy: 0.8699 - val_loss: 0.9594 - val_categorical_accuracy: 0.6656\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 1351s 2s/step - loss: 0.2860 - categorical_accuracy: 0.8941 - val_loss: 0.9772 - val_categorical_accuracy: 0.6608\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 1255s 2s/step - loss: 0.2379 - categorical_accuracy: 0.9133 - val_loss: 1.0586 - val_categorical_accuracy: 0.6548\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 895s 1s/step - loss: 0.1892 - categorical_accuracy: 0.9303 - val_loss: 1.2131 - val_categorical_accuracy: 0.6383\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 893s 1s/step - loss: 0.1511 - categorical_accuracy: 0.9446 - val_loss: 1.3698 - val_categorical_accuracy: 0.6390\n"
     ]
    }
   ],
   "source": [
    "#Without drop 0.25\n",
    "print(\"TRAINING FOR MODEL1\")\n",
    "train_generator(model1, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMYm2hFqiUfu"
   },
   "outputs": [],
   "source": [
    "print(\"TRAINING FOR MODEL2\")\n",
    "train_generator(model2, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oHhaNdgSiUsA"
   },
   "outputs": [],
   "source": [
    "print(\"TRAINING FOR MODEL3\")\n",
    "train_generator(model3, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FOR MODEL3\n",
      "Epoch 1/20\n",
      "600/600 [==============================] - 783s 1s/step - loss: 0.9205 - categorical_accuracy: 0.5572 - val_loss: 0.8036 - val_categorical_accuracy: 0.6181\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 783s 1s/step - loss: 0.7501 - categorical_accuracy: 0.6650 - val_loss: 0.7679 - val_categorical_accuracy: 0.6400\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 797s 1s/step - loss: 0.6825 - categorical_accuracy: 0.7056 - val_loss: 0.7427 - val_categorical_accuracy: 0.6698\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 786s 1s/step - loss: 0.6252 - categorical_accuracy: 0.7358 - val_loss: 0.7199 - val_categorical_accuracy: 0.6687\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 786s 1s/step - loss: 0.5811 - categorical_accuracy: 0.7544 - val_loss: 0.7424 - val_categorical_accuracy: 0.6660\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 961s 2s/step - loss: 0.5289 - categorical_accuracy: 0.7839 - val_loss: 0.7496 - val_categorical_accuracy: 0.6769\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 799s 1s/step - loss: 0.4829 - categorical_accuracy: 0.8093 - val_loss: 0.7860 - val_categorical_accuracy: 0.6746\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 785s 1s/step - loss: 0.4396 - categorical_accuracy: 0.8269 - val_loss: 0.8218 - val_categorical_accuracy: 0.6660\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 790s 1s/step - loss: 0.3963 - categorical_accuracy: 0.8466 - val_loss: 0.8293 - val_categorical_accuracy: 0.6729\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 784s 1s/step - loss: 0.3519 - categorical_accuracy: 0.8649 - val_loss: 0.8774 - val_categorical_accuracy: 0.6692\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 797s 1s/step - loss: 0.3073 - categorical_accuracy: 0.8830 - val_loss: 0.9935 - val_categorical_accuracy: 0.6538\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 790s 1s/step - loss: 0.2721 - categorical_accuracy: 0.8995 - val_loss: 0.9810 - val_categorical_accuracy: 0.6742\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 810s 1s/step - loss: 0.2374 - categorical_accuracy: 0.9139 - val_loss: 1.0678 - val_categorical_accuracy: 0.6556\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 798s 1s/step - loss: 0.2062 - categorical_accuracy: 0.9249 - val_loss: 1.1173 - val_categorical_accuracy: 0.6660\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING FOR MODEL7\")\n",
    "train_generator(model7, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5s3yzfC9ZDlz"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "-1h29A9uaPWz",
    "outputId": "0341495a-456f-4af3-d20b-bc612ca064ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000/6000 [==============================] - 90s 15ms/step\n",
      "1.3527190974553427\n",
      "0.649\n"
     ]
    }
   ],
   "source": [
    "#Without drop 0.25\n",
    "print(\"TESTING FOR MODEL1\")\n",
    "loss, accuracy = model1.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy) # test acc is 64.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEywcGoVkpkw"
   },
   "outputs": [],
   "source": [
    "print(\"TESTING FOR MODEL2\")\n",
    "loss, accuracy = model2.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFtqPDnKkpqV"
   },
   "outputs": [],
   "source": [
    "print(\"TESTING FOR MODEL3\")\n",
    "loss, accuracy = model3.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING FOR MODEL7\n",
      "6000/6000 [==============================] - 67s 11ms/step\n",
      "1.1489095962842306\n",
      "0.6581666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING FOR MODEL7\")\n",
    "loss, accuracy = model7.evaluate(x = test_x_, y = test_y, verbose = 1)\n",
    "\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model\n",
    "\n",
    "\n",
    "#### UniDirectional RNN\n",
    "\n",
    "model6: acc:61.45 (no embd drop, lstm dropout = 0.5, reccr drop = 0.1), approx. training time: 96mins\n",
    "\n",
    "model4: acc:64.03 (embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.1), approx. training time: 75mins\n",
    "\n",
    "model5: acc:61.75 (embd drop = 0.25, lstm dropout = 0.5, reccr drop = 0.2), approx. training time: 85mins\n",
    "\n",
    "\n",
    "#### BiDirectional RNN\n",
    "\n",
    "model1: acc:61.38 (no embd drop, lstmdrop = 0.5, recdrop = 0.1), approx. training time: 145mins\n",
    "\n",
    "model2: acc:63.93 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.1), approx. training time: 145mins\n",
    "\n",
    "model3: acc:63.88 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2), approx. training time: 140mins\n",
    "\n",
    "model7: acc:65.81 (embd drop = 0.25, lstmdrop = 0.5, recdrop = 0.2, merge_mode = 'ave'), approx. training time: 150mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in Uni Directional when having dropout for each embedding layer, lastm layer and reccurent dropout we get the highest accuracy during evaluation as overfitting in the training set has been reduced and thus the model is able to predict the unseen with higher accuracy. Also has less training time than the other models as the number of neurons that are less significant are dropped out.\n",
    "\n",
    "In Bi Directional we can see that model7 achieves high accuracy with merge mode as average but takes more time for training. Considering the tradeoff between accuracy and training time we can conclude that the configuration in model2 is best performing.\n",
    "\n",
    "The above reported are the models that give some meaningful change/insight into the performance of the model for small variation in hyper parameters among all the other models that were tried."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment-3.1.1.Document-Level-Sentiment-Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
