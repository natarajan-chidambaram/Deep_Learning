{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3.1. Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group 09\n",
    "\n",
    "Abhishek Mahadevan Raju (1306162), Priya Sivasubramanian (1378635), Natarajan Chidambaram (1358111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Aspect-level Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an attention-based aspect-level sentiment classification model with RNN. Your model shall\n",
    "include:\n",
    "\n",
    "- RNN network that learns sentence representation from input sequences.\n",
    "- Attention network that assigns attention score over a sequence of RNN hidden states based on aspect terms representation.\n",
    "- Fully connected network that predicts sentiment label, given the representation weighted by the attention score.\n",
    "\n",
    "Train the model by using data iterator and batch generator. Evaluate the trained model on\n",
    "the provided test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import codecs\n",
    "import operator\n",
    "import numpy as np\n",
    "import re\n",
    "from time import time\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import _pickle as cPickle\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dense, Lambda, Dropout, LSTM\n",
    "from keras.layers import Reshape, Activation, RepeatVector, concatenate, Concatenate, Dot, Multiply\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "import keras.optimizers as opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_path = 'data/aspect_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path = 'data/doc_level'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_regex = re.compile('^[+-]?[0-9]+\\.?[0-9]*$')\n",
    "\n",
    "def is_number(token):\n",
    "    return bool(num_regex.match(token))\n",
    "\n",
    "\n",
    "def create_vocab(domain, aspect_path, doc_path, maxlen=0, vocab_size=0):\n",
    "    \n",
    "    assert domain in ['res_14', 'lt_14', 'res_15', 'res_16']\n",
    "\n",
    "    file_list = [os.path.join(aspect_path,'%s_train_sentence.txt'%(domain)),\n",
    "                 os.path.join(aspect_path,'%s_test_sentence.txt'%(domain))]\n",
    "\n",
    "    if domain in ['lt_14']:\n",
    "        file_list.append(os.path.join(doc_path,'amazon_electronics_text.txt'))\n",
    "    else:\n",
    "        file_list.append(os.path.join(doc_path,'yelp14_text.txt'))\n",
    "\n",
    "    print ('Creating vocab ...')\n",
    "\n",
    "    total_words, unique_words = 0, 0\n",
    "    word_freqs = {}\n",
    "\n",
    "    for f in file_list:\n",
    "        top = 0\n",
    "        fin = codecs.open(f, 'r', 'utf-8')\n",
    "        for line in fin:\n",
    "            words = line.split()\n",
    "            if maxlen > 0 and len(words) > maxlen:\n",
    "                continue\n",
    "            for w in words:\n",
    "                if not is_number(w):\n",
    "                    try:\n",
    "                        word_freqs[w] += 1\n",
    "                    except KeyError:\n",
    "                        unique_words += 1\n",
    "                        word_freqs[w] = 1\n",
    "                    total_words += 1\n",
    "\n",
    "    print ('  %i total words, %i unique words' % (total_words, unique_words))\n",
    "    sorted_word_freqs = sorted(word_freqs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    vocab = {'<pad>':0, '<unk>':1, '<num>':2}\n",
    "    index = len(vocab)\n",
    "    for word, _ in sorted_word_freqs:\n",
    "        vocab[word] = index\n",
    "        index += 1\n",
    "        if vocab_size > 0 and index > vocab_size + 2:\n",
    "            break\n",
    "    if vocab_size > 0:\n",
    "        print (' keep the top %i words' % vocab_size)\n",
    "\n",
    "    \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_aspect(domain, aspect_path, phase, vocab, maxlen):\n",
    "    \n",
    "    assert domain in ['res_14', 'lt_14', 'res_15', 'res_16']\n",
    "    assert phase in ['train', 'test']\n",
    "    \n",
    "    print ('Preparing dataset ...')\n",
    "\n",
    "    data_x, data_y, aspect = [], [], []\n",
    "    polarity_category = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "    \n",
    "    if(phase == 'train'):\n",
    "        file_names = [os.path.join(aspect_path,'%s_%s_sentence.txt'%(domain, phase)),\n",
    "                   os.path.join(aspect_path,'%s_%s_polarity.txt'%(domain, phase)),\n",
    "                   os.path.join(aspect_path,'%s_%s_term.txt'%(domain, phase))]\n",
    "    else:\n",
    "        file_names = [os.path.join(aspect_path, '%s_%s_sentence.txt'%(domain, phase)),\n",
    "                   os.path.join(aspect_path, '%s_%s_polarity.txt'%(domain, phase)),\n",
    "                   os.path.join(aspect_path, '%s_%s_term.txt'%(domain, phase))]\n",
    "\n",
    "    num_hit, unk_hit, total = 0., 0., 0.\n",
    "    maxlen_x = 0\n",
    "    maxlen_aspect = 0\n",
    "\n",
    "    files = [open(i, 'r') for i in file_names]\n",
    "    for rows in zip(*files):\n",
    "        content = rows[0].strip().split()\n",
    "        polarity = rows[1].strip()\n",
    "        aspect_content = rows[2].strip().split()\n",
    "\n",
    "        if maxlen > 0 and len(content) > maxlen:\n",
    "            continue\n",
    "\n",
    "        content_indices = []\n",
    "        if len(content) == 0:\n",
    "            content_indices.append(vocab['<unk>'])\n",
    "            unk_hit += 1\n",
    "        for word in content:\n",
    "            if is_number(word):\n",
    "                content_indices.append(vocab['<num>'])\n",
    "                num_hit += 1\n",
    "            elif word in vocab:\n",
    "                content_indices.append(vocab[word])\n",
    "            else:\n",
    "                content_indices.append(vocab['<unk>'])\n",
    "                unk_hit += 1\n",
    "            total += 1\n",
    "\n",
    "        data_x.append(content_indices)\n",
    "        data_y.append(polarity_category[polarity])\n",
    "\n",
    "        aspect_indices = []\n",
    "        if len(aspect_content) == 0:\n",
    "            aspect_indices.append(vocab['<unk>'])\n",
    "            unk_hit += 1\n",
    "        for word in aspect_content:\n",
    "            if is_number(word):\n",
    "                aspect_indices.append(vocab['<num>'])\n",
    "            elif word in vocab:\n",
    "                aspect_indices.append(vocab[word])\n",
    "            else:\n",
    "                aspect_indices.append(vocab['<unk>'])\n",
    "        aspect.append(aspect_indices)\n",
    "\n",
    "        if maxlen_x < len(content_indices):\n",
    "            maxlen_x = len(content_indices)\n",
    "        if maxlen_aspect < len(aspect_indices):\n",
    "            maxlen_aspect = len(aspect_indices)\n",
    "\n",
    "\n",
    "    \n",
    "    print ('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' % (100*num_hit/total, 100*unk_hit/total))\n",
    "    return data_x, data_y, aspect, maxlen_x, maxlen_aspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_aspect(vocab, domain, aspect_path, maxlen=0):\n",
    "    \n",
    "    assert domain in ['res_14', 'lt_14', 'res_15', 'res_16']\n",
    "\n",
    "    train_x, train_y, train_aspect, train_maxlen, train_maxlen_aspect = \\\n",
    "    read_dataset_aspect(domain, aspect_path, 'train', vocab, maxlen)\n",
    "    \n",
    "    test_x, test_y, test_aspect, test_maxlen, test_maxlen_aspect = \\\n",
    "    read_dataset_aspect(domain, aspect_path, 'test', vocab, maxlen)\n",
    "    \n",
    "    overal_maxlen = max(train_maxlen, test_maxlen)\n",
    "    overal_maxlen_aspect = max(train_maxlen_aspect, test_maxlen_aspect)\n",
    "\n",
    "    print (' Overal_maxlen: %s' % overal_maxlen)\n",
    "    print (' Overal_maxlen_aspect:%s '% overal_maxlen_aspect)\n",
    "    \n",
    "    return train_x, train_y, train_aspect, test_x, test_y, test_aspect, overal_maxlen, overal_maxlen_aspect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(vocab, text_path, label_path, skip_top, skip_len, replace_non_vocab):\n",
    "    \n",
    "    data = []\n",
    "    label = [] # {pos: 0, neg: 1, neu: 2}\n",
    "    f = codecs.open(text_path, 'r', 'utf-8')\n",
    "    f_l = codecs.open(label_path, 'r', 'utf-8')\n",
    "    num_hit, unk_hit, skip_top_hit, total = 0., 0., 0., 0.\n",
    "    pos_count, neg_count, neu_count = 0, 0, 0\n",
    "    max_len = 0\n",
    "\n",
    "    for line, score in zip(f, f_l):\n",
    "        word_indices = []\n",
    "        words = line.split()\n",
    "        if skip_len > 0 and len(words) > skip_len:\n",
    "            continue\n",
    "\n",
    "        score = float(score.strip())\n",
    "        if score < 3:\n",
    "            neg_count += 1\n",
    "            label.append(1)\n",
    "        elif score > 3:\n",
    "            pos_count += 1\n",
    "            label.append(0)\n",
    "        else:\n",
    "            neu_count += 1\n",
    "            label.append(2)\n",
    "            \n",
    "        for word in words:\n",
    "            if bool(num_regex.match(word)):\n",
    "                word_indices.append(vocab['<num>'])\n",
    "                num_hit += 1\n",
    "            elif word in vocab:\n",
    "                word_ind = vocab[word]\n",
    "                if skip_top > 0 and word_ind < skip_top + 3:\n",
    "                    skip_top_hit += 1\n",
    "                else:\n",
    "                    word_indices.append(word_ind)\n",
    "            else:\n",
    "                if replace_non_vocab:\n",
    "                    word_indices.append(vocab['<unk>'])\n",
    "                unk_hit += 1\n",
    "            total += 1\n",
    "\n",
    "        if len(word_indices) > max_len:\n",
    "            max_len = len(word_indices)\n",
    "\n",
    "        data.append(word_indices)\n",
    "\n",
    "    f.close()\n",
    "    f_l.close()\n",
    "\n",
    "    print('  <num> hit rate: %.2f%%, <unk> hit rate: %.2f%%' %(100*num_hit/total, 100*unk_hit/total))\n",
    "\n",
    "    return np.array(data), np.array(label), max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(domain, aspect_path, doc_path, vocab_size, maxlen=0):\n",
    "    \n",
    "    vocab = create_vocab(domain, aspect_path, doc_path, maxlen, vocab_size)\n",
    "\n",
    "    train_x, train_y, train_aspect, test_x, test_y, test_aspect, overal_maxlen, overal_maxlen_aspect = get_data_aspect(vocab, domain, aspect_path)\n",
    "\n",
    "    return train_x, train_y, train_aspect, test_x, test_y, test_aspect, vocab, overal_maxlen, overal_maxlen_aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vocab ...\n",
      "  3498349 total words, 39278 unique words\n",
      " keep the top 10000 words\n",
      "Preparing dataset ...\n",
      "  <num> hit rate: 0.99%, <unk> hit rate: 1.16%\n",
      "Preparing dataset ...\n",
      "  <num> hit rate: 1.18%, <unk> hit rate: 1.13%\n",
      " Overal_maxlen: 82\n",
      " Overal_maxlen_aspect:7 \n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, train_aspect, test_x, test_y, test_aspect, vocab, overal_maxlen, overal_maxlen_aspect = prepare_data('lt_14', aspect_path, doc_path, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation size: 462\n"
     ]
    }
   ],
   "source": [
    "# Pad aspect sentences sequences for mini-batch processing\n",
    "train_x = sequence.pad_sequences(train_x, maxlen=overal_maxlen)\n",
    "test_x = sequence.pad_sequences(test_x, maxlen=overal_maxlen)\n",
    "train_aspect = sequence.pad_sequences(train_aspect, maxlen=overal_maxlen_aspect)\n",
    "test_aspect = sequence.pad_sequences(test_aspect, maxlen=overal_maxlen_aspect)\n",
    "\n",
    "# convert y to categorical labels\n",
    "train_y = to_categorical(train_y, 3)\n",
    "test_y = to_categorical(test_y, 3)\n",
    "\n",
    "validation_ratio = 0.2\n",
    "validation_size = int(len(train_x) * validation_ratio)\n",
    "print ('Validation size: %s' % validation_size)\n",
    "\n",
    "\n",
    "dev_x = train_x[:validation_size]\n",
    "dev_y = train_y[:validation_size]\n",
    "dev_aspect = train_aspect[:validation_size]\n",
    "\n",
    "train_x = train_x[validation_size:]\n",
    "train_y = train_y[validation_size:]\n",
    "train_aspect = train_aspect[validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(data_path, file_name):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'rb')\n",
    "    read_file = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "    return read_file\n",
    "\n",
    "def save_pickle(data_path, file_name, data):\n",
    "\n",
    "    f = open(os.path.join(data_path, file_name), 'wb')\n",
    "    cPickle.dump(data, f)\n",
    "    print(\" file saved to: %s\"%(os.path.join(data_path, file_name)))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " file saved to: data/aspect_level\\all_vocab.pkl\n",
      " file saved to: data/aspect_level\\train_x.pkl\n",
      " file saved to: data/aspect_level\\train_y.pkl\n",
      " file saved to: data/aspect_level\\dev_x.pkl\n",
      " file saved to: data/aspect_level\\dev_y.pkl\n",
      " file saved to: data/aspect_level\\test_x.pkl\n",
      " file saved to: data/aspect_level\\test_y.pkl\n",
      " file saved to: data/aspect_level\\train_aspect.pkl\n",
      " file saved to: data/aspect_level\\dev_aspect.pkl\n",
      " file saved to: data/aspect_level\\test_aspect.pkl\n"
     ]
    }
   ],
   "source": [
    "save_pickle(aspect_path, 'all_vocab.pkl', vocab)\n",
    "\n",
    "save_pickle(aspect_path, 'train_x.pkl', train_x)\n",
    "save_pickle(aspect_path, 'train_y.pkl', train_y)\n",
    "save_pickle(aspect_path, 'dev_x.pkl', dev_x)\n",
    "save_pickle(aspect_path, 'dev_y.pkl', dev_y)\n",
    "save_pickle(aspect_path, 'test_x.pkl', test_x)\n",
    "save_pickle(aspect_path, 'test_y.pkl', test_y)\n",
    "\n",
    "save_pickle(aspect_path, 'train_aspect.pkl', train_aspect)\n",
    "save_pickle(aspect_path, 'dev_aspect.pkl', dev_aspect)\n",
    "save_pickle(aspect_path, 'test_aspect.pkl', test_aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = read_pickle(aspect_path, 'all_vocab.pkl')\n",
    "\n",
    "train_x = read_pickle(aspect_path, 'train_x.pkl')\n",
    "train_y = read_pickle(aspect_path, 'train_y.pkl')\n",
    "dev_x = read_pickle(aspect_path, 'dev_x.pkl')\n",
    "dev_y = read_pickle(aspect_path, 'dev_y.pkl')\n",
    "test_x = read_pickle(aspect_path, 'test_x.pkl')\n",
    "test_y = read_pickle(aspect_path, 'test_y.pkl')\n",
    "\n",
    "train_aspect = read_pickle(aspect_path, 'train_aspect.pkl')\n",
    "dev_aspect = read_pickle(aspect_path, 'dev_aspect.pkl')\n",
    "test_aspect = read_pickle(aspect_path, 'test_aspect.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataiterator():\n",
    "    '''\n",
    "      1) Iteration over minibatches using next(); call reset() between epochs to randomly shuffle the data\n",
    "      2) Access to the entire dataset using all()\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, aspect_data, seq_length=32, decoder_dim=300, batch_size=32):\n",
    "        \n",
    "        len_aspect_data = len(aspect_data[0])\n",
    "        \n",
    "        self.X_aspect = aspect_data[0] \n",
    "        self.y_aspect = aspect_data[1]\n",
    "        self.aspect_terms = aspect_data[2]\n",
    "        \n",
    "        self.num_data = len_aspect_data\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.reset() # initial: shuffling examples and set index to 0\n",
    "    \n",
    "    def __iter__(self): # iterates data\n",
    "        return self\n",
    "\n",
    "\n",
    "    def reset(self): # initials\n",
    "        self.idx = 0\n",
    "        self.order = np.random.permutation(self.num_data) # shuffling examples by providing randomized ids \n",
    "        \n",
    "    def __next__(self): # return model inputs - outputs per batch\n",
    "        \n",
    "        X_ids = [] # hold ids per batch \n",
    "        while len(X_ids) < self.batch_size:\n",
    "            X_id = self.order[self.idx] # copy random id from initial shuffling\n",
    "            X_ids.append(X_id)\n",
    "            self.idx += 1 # \n",
    "            if self.idx >= self.num_data: # exception if all examples of data have been seen (iterated)\n",
    "                self.reset()\n",
    "                raise StopIteration()\n",
    "                \n",
    "        batch_X_aspect = self.X_aspect[np.array(X_ids)] # X values (encoder input) per batch\n",
    "        batch_y_aspect = self.y_aspect[np.array(X_ids)] # y_in values (decoder input) per batch\n",
    "        batch_aspect_terms = self.aspect_terms[np.array(X_ids)]\n",
    "        \n",
    "        \n",
    "        return batch_X_aspect, batch_y_aspect, batch_aspect_terms\n",
    "\n",
    "          \n",
    "    def all(self): # return all data examples\n",
    "        return self.X_aspect, self.y_aspect, self.aspect_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "overal_maxlen = 82\n",
    "overal_maxlen_aspect = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_softmax(x, axis=1):\n",
    "            \"\"\"Softmax activation function.\n",
    "            # Arguments\n",
    "                x : Tensor.\n",
    "                axis: Integer, axis along which the softmax normalization is applied.\n",
    "            # Returns\n",
    "                Tensor, output of softmax transformation.\n",
    "            # Raises\n",
    "                ValueError: In case `dim(x) == 1`.\n",
    "            \"\"\"\n",
    "            ndim = K.ndim(x)\n",
    "            if ndim == 2:\n",
    "                return K.softmax(x)\n",
    "            elif ndim > 2:\n",
    "                e = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
    "                s = K.sum(e, axis=axis, keepdims=True)\n",
    "                return e / s\n",
    "            else:\n",
    "                raise ValueError('Cannot apply softmax to a tensor that is 1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeator = RepeatVector(overal_maxlen, name='repeator_att')\n",
    "concatenator = Concatenate(axis=-1, name='concator_att')\n",
    "densor1 = Dense(300, activation = \"tanh\", name='densor1_att')\n",
    "densor2 = Dense(1, activation = \"relu\", name='densor2_att')\n",
    "activator = Activation(custom_softmax, name='attention_weights')\n",
    "dotor = Dot(axes = 1, name='dotor_att')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(keys, query):\n",
    "    \n",
    "    query = repeator(query)\n",
    "    print(\"query shape: %s\" %str(query._keras_shape))\n",
    "    concat = concatenator([keys, query])\n",
    "    print(\"concat shape: %s\" %str(concat._keras_shape))\n",
    "    e1 = densor1(concat)\n",
    "    print(\"e1 shape: %s\" %str(e1._keras_shape))\n",
    "    e2 = densor2(e1)\n",
    "    print(\"e2 shape: %s\" %str(e2._keras_shape))\n",
    "    alphas = activator(e2)\n",
    "    print(\"alphas shape: %s\" %str(alphas._keras_shape))\n",
    "    context = dotor([alphas, keys])\n",
    "    print(\"context shape: %s\" %str(context._keras_shape))\n",
    "    \n",
    "    return context, alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(Layer):\n",
    "  \n",
    "    def __init__(self, mask_zero=True, **kwargs):\n",
    "        self.mask_zero = mask_zero\n",
    "        self.supports_masking = True\n",
    "        super(Average, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.mask_zero:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
    "        else:\n",
    "            return K.mean(x, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def compute_mask(self, x, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.5\n",
    "recurrent_dropout = 0.2\n",
    "vocab_size = len(vocab)\n",
    "num_outputs = 3 # labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Inputs #####\n",
    "sentence_input = Input(shape=(overal_maxlen,), dtype='int32', name='sentence_input')\n",
    "aspect_input = Input(shape=(overal_maxlen_aspect,), dtype='int32', name='aspect_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### construct word embedding layer #####\n",
    "word_emb = Embedding(vocab_size, 300, mask_zero=True, name='word_emb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use average term embs as aspect embedding\n"
     ]
    }
   ],
   "source": [
    "### represent aspect as averaged word embedding ###\n",
    "print ('use average term embs as aspect embedding')\n",
    "aspect_term_embs = word_emb(aspect_input)\n",
    "aspect_embs = Average(mask_zero=True, name='aspect_emb')(aspect_term_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 300)\n"
     ]
    }
   ],
   "source": [
    "print(aspect_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sentence representation ###\n",
    "sentence_embs = word_emb(sentence_input) # from aspect-level domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 82, 300)\n",
      "(?, 7, 300)\n"
     ]
    }
   ],
   "source": [
    "print(sentence_embs.shape)\n",
    "print(aspect_term_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = Dropout(0.35)(sentence_embs)\n",
    "sentence_lstm = LSTM(300, return_sequences=True, dropout=dropout, \n",
    "                     recurrent_dropout=recurrent_dropout, name='lstmSentence')(drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence_lstm = rnns(sentence_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 82, 300)\n",
      "(?, 300)\n",
      "(?, ?, 300)\n"
     ]
    }
   ],
   "source": [
    "print(sentence_embs.shape)\n",
    "print(aspect_embs.shape)\n",
    "print(sentence_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aspect_lstm = rnna(aspect_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shape: (None, 82, 300)\n",
      "concat shape: (None, 82, 600)\n",
      "e1 shape: (None, 82, 300)\n",
      "e2 shape: (None, 82, 1)\n",
      "alphas shape: (None, 82, 1)\n",
      "context shape: (None, 1, 300)\n"
     ]
    }
   ],
   "source": [
    "att_context, att_weights = attention(sentence_lstm, aspect_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_output = Dense(num_outputs, name='dense_1')(att_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_output = Reshape((num_outputs,))(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_probs = Activation('softmax', name='aspect_model')(sentence_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[sentence_input, aspect_input], outputs=[aspect_probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_input (InputLayer)     (None, 82)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "aspect_input (InputLayer)       (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_emb (Embedding)            multiple             3000900     aspect_input[0][0]               \n",
      "                                                                 sentence_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 82, 300)      0           word_emb[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "aspect_emb (Average)            (None, 300)          0           word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstmSentence (LSTM)             (None, 82, 300)      721200      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeator_att (RepeatVector)     (None, 82, 300)      0           aspect_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concator_att (Concatenate)      (None, 82, 600)      0           lstmSentence[0][0]               \n",
      "                                                                 repeator_att[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "densor1_att (Dense)             (None, 82, 300)      180300      concator_att[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "densor2_att (Dense)             (None, 82, 1)        301         densor1_att[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 82, 1)        0           densor2_att[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dotor_att (Dot)                 (None, 1, 300)       0           attention_weights[1][0]          \n",
      "                                                                 lstmSentence[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1, 3)         903         dotor_att[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 3)            0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "aspect_model (Activation)       (None, 3)            0           reshape_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,903,604\n",
      "Trainable params: 3,903,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = opt.RMSprop(lr=0.001, rho=0.9, epsilon=1e-06, clipnorm=10, clipvalue=0)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer,\n",
    "              loss={'aspect_model': 'categorical_crossentropy'},\n",
    "              loss_weights = {'aspect_model': 1},\n",
    "              metrics = {'aspect_model': 'categorical_accuracy'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_epoch = len(train_x)/batch_size\n",
    "batch_train_iter = Dataiterator([train_x, train_y, train_aspect], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps_epoch = len(dev_x)/batch_size\n",
    "batch_val_iter = Dataiterator([dev_x, dev_y, dev_aspect], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train_generator(model, batch_train_iter, batch_val_iter):\n",
    "    \n",
    "    earlystop_callbacks = [EarlyStopping(monitor='val_loss', patience=10),\n",
    "                     ModelCheckpoint(filepath=os.path.join('./','{epoch:02d}-{loss:.2f}.check'), \\\n",
    "                                     monitor='val_loss', save_best_only=False, \\\n",
    "                                     save_weights_only=True)\n",
    "                     ]\n",
    "    \n",
    "    def train_gen():\n",
    "        while True:\n",
    "            train_batches = [[[X, aspect], [y]] for X, y, aspect in batch_train_iter]\n",
    "            for train_batch in train_batches:\n",
    "                yield train_batch\n",
    "                \n",
    "    def val_gen():\n",
    "        while True:\n",
    "            val_batches = [[[X, aspect], [y]] for X, y, aspect in batch_val_iter]\n",
    "            for val_batch in val_batches:\n",
    "                yield val_batch\n",
    "\n",
    "                \n",
    "    history = model.fit_generator(train_gen(), validation_data=val_gen(), \\\n",
    "                                  validation_steps=val_steps_epoch, steps_per_epoch=train_steps_epoch, \\\n",
    "                                  epochs = 20, callbacks = earlystop_callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "58/57 [==============================] - 26s 452ms/step - loss: 1.0162 - categorical_accuracy: 0.5469 - val_loss: 0.8591 - val_categorical_accuracy: 0.6500\n",
      "Epoch 2/20\n",
      "58/57 [==============================] - 21s 370ms/step - loss: 0.7834 - categorical_accuracy: 0.6643 - val_loss: 0.8469 - val_categorical_accuracy: 0.6167\n",
      "Epoch 3/20\n",
      "58/57 [==============================] - 22s 372ms/step - loss: 0.6562 - categorical_accuracy: 0.7435 - val_loss: 0.8433 - val_categorical_accuracy: 0.6458\n",
      "Epoch 4/20\n",
      "58/57 [==============================] - 22s 375ms/step - loss: 0.5827 - categorical_accuracy: 0.7737 - val_loss: 0.8699 - val_categorical_accuracy: 0.6229\n",
      "Epoch 5/20\n",
      "58/57 [==============================] - 22s 374ms/step - loss: 0.5354 - categorical_accuracy: 0.8055 - val_loss: 0.9380 - val_categorical_accuracy: 0.6208\n",
      "Epoch 6/20\n",
      "58/57 [==============================] - 21s 360ms/step - loss: 0.4608 - categorical_accuracy: 0.8378 - val_loss: 0.9233 - val_categorical_accuracy: 0.6479\n",
      "Epoch 7/20\n",
      "58/57 [==============================] - 22s 377ms/step - loss: 0.4404 - categorical_accuracy: 0.8367 - val_loss: 1.1081 - val_categorical_accuracy: 0.6042\n",
      "Epoch 8/20\n",
      "58/57 [==============================] - 22s 374ms/step - loss: 0.4299 - categorical_accuracy: 0.8405 - val_loss: 0.9178 - val_categorical_accuracy: 0.6438\n",
      "Epoch 9/20\n",
      "58/57 [==============================] - 21s 357ms/step - loss: 0.3799 - categorical_accuracy: 0.8610 - val_loss: 1.0058 - val_categorical_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "58/57 [==============================] - 21s 363ms/step - loss: 0.3481 - categorical_accuracy: 0.8831 - val_loss: 1.0520 - val_categorical_accuracy: 0.6292\n",
      "Epoch 11/20\n",
      "58/57 [==============================] - 22s 384ms/step - loss: 0.3417 - categorical_accuracy: 0.8750 - val_loss: 1.1221 - val_categorical_accuracy: 0.6229\n",
      "Epoch 12/20\n",
      "58/57 [==============================] - 22s 385ms/step - loss: 0.3129 - categorical_accuracy: 0.8836 - val_loss: 1.2209 - val_categorical_accuracy: 0.6375\n",
      "Epoch 13/20\n",
      "58/57 [==============================] - 21s 368ms/step - loss: 0.3149 - categorical_accuracy: 0.8788 - val_loss: 1.0402 - val_categorical_accuracy: 0.6188\n"
     ]
    }
   ],
   "source": [
    "train_generator(model, batch_train_iter, batch_val_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "2.098953261270792\n",
      "0.5924764884676679\n"
     ]
    }
   ],
   "source": [
    "# batch 64, 130secs on avg\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.7008815278827583\n",
      "0.5956112863875481\n"
     ]
    }
   ],
   "source": [
    "# batch 32, 130secs\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.7290794946556929\n",
      "0.6018808773692499\n"
     ]
    }
   ],
   "source": [
    "# batch 32, dropout 0.25 @embd layer, 160secs\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.747211235817697\n",
      "0.6191222564927463\n"
     ]
    }
   ],
   "source": [
    "# batch 32, dropout 0.35 @embd layer, 160secs\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.1072117927306124\n",
      "0.6253918493429321\n"
     ]
    }
   ],
   "source": [
    "# on avg 170secs trainign time\n",
    "# batch 32, dropout 0.35 @embd layer, recurrent dropout 0.2\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.2361519788873607\n",
      "0.6159874621229859\n"
     ]
    }
   ],
   "source": [
    "#But more training time than others 200s on avg\n",
    "# batch 32, dropout 0.35 @embd layer, recurrent dropout 0.25\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "1.1464755486545144\n",
      "0.6050156752891301\n"
     ]
    }
   ],
   "source": [
    "#But more training time than others, 160s on avg\n",
    "# batch 32, dropout 0.35 @embd layer, recurrent dropout 0.2, dropout 0.6 @lstm layer\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 2s 3ms/step\n",
      "0.962729321004455\n",
      "0.6206896551724138\n"
     ]
    }
   ],
   "source": [
    "# training time 270secs\n",
    "# batch 32, dropout 0.35 @embd layer, recurrent dropout 0.2, dropout 0.6 @lstm layer, TimeDistributed\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638/638 [==============================] - 3s 4ms/step\n",
      "1.015622421865553\n",
      "0.5736677115987461\n"
     ]
    }
   ],
   "source": [
    "# training time 290secs\n",
    "# batch 32, dropout 0.35 @embd layer, recurrent dropout 0.2, TimeDistributed\n",
    "loss, accuracy = model.evaluate([test_x, test_aspect], test_y, verbose = 1)\n",
    "print(loss)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Upon looking into the performance of the model on test set and its training time we can say that the following configuration works better.\n",
    "\n",
    "dropout 0.35 after embd layer, recurrent dropout 0.2, lstm dropout 0.5"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Doc_level_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
